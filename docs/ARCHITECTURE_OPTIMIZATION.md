# ç³»ç»Ÿæ¶æ„ä¼˜åŒ–æ–¹æ¡ˆ

> ç‰ˆæœ¬: v1.0
> æ—¥æœŸ: 2025-12-16
> åŸºäº: æ¶æ„æ·±åº¦åˆ†ææŠ¥å‘Š + MediaCrawlerå¼€æºé¡¹ç›®å€Ÿé‰´

---

## ä¸€ã€å½“å‰æ¶æ„é—®é¢˜æ€»è§ˆ

### 1.1 æ¶æ„è¯„åˆ†

| ç»´åº¦ | å½“å‰è¯„åˆ† | ç›®æ ‡è¯„åˆ† | å·®è· |
|------|---------|---------|------|
| æ¶æ„æ¸…æ™°åº¦ | â­â­â­ | â­â­â­â­â­ | å±‚é—´è€¦åˆä¸¥é‡ |
| å¯æ‰©å±•æ€§ | â­â­ | â­â­â­â­ | æ–°å¢åŠŸèƒ½éœ€æ”¹å¤šä¸ªæ–‡ä»¶ |
| æ€§èƒ½ | â­â­â­ | â­â­â­â­â­ | HTTP/CookieæŸ¥è¯¢ç“¶é¢ˆ |
| å¯æµ‹è¯•æ€§ | â­â­ | â­â­â­â­ | ç¼ºä¹æ¥å£æŠ½è±¡ |
| å®‰å…¨æ€§ | â­â­â­â­ | â­â­â­â­â­ | ç¼ºè®¿é—®æ§åˆ¶ |

### 1.2 æ ¸å¿ƒé—®é¢˜æ¸…å•

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸ”´ é«˜ä¼˜å…ˆçº§é—®é¢˜                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Cookieè·å– O(n) å¤æ‚åº¦ - æ¯æ¬¡è¯·æ±‚éå†æ‰€æœ‰Cookie          â”‚
â”‚ 2. HTTP Session é‡å¤åˆ›å»º - æ— è¿æ¥æ± å¤ç”¨                     â”‚
â”‚ 3. æ‰¹é‡è¯·æ±‚ä¸²è¡Œå¤„ç† - 20æ¡éœ€300ç§’ vs åº”è¯¥15ç§’               â”‚
â”‚ 4. æ— IPä»£ç†æ±  - å®¹æ˜“è¢«å°ç¦                                  â”‚
â”‚ 5. é…ç½®ç¡¬ç¼–ç  - ä¿®æ”¹éœ€é‡æ–°éƒ¨ç½²                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    ğŸŸ¡ ä¸­ä¼˜å…ˆçº§é—®é¢˜                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 6. å¼‚å¸¸å¤„ç†é‡å¤ - ç›¸åŒé€»è¾‘å‡ºç°5+æ¬¡                          â”‚
â”‚ 7. è·¯ç”±å±‚ä¸šåŠ¡é€»è¾‘è¿‡é‡ - Cookieè·å–åº”åœ¨æœåŠ¡å±‚                â”‚
â”‚ 8. å…¨å±€å•ä¾‹ - å¤šè¿›ç¨‹æ— æ³•åŒæ­¥çŠ¶æ€                            â”‚
â”‚ 9. æ— è®¿é—®æ§åˆ¶ - APIæ— è®¤è¯                                   â”‚
â”‚ 10. å­˜å‚¨å±‚æœªæŠ½è±¡ - åªæœ‰å†…å­˜å­˜å‚¨                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## äºŒã€ç›®æ ‡æ¶æ„è®¾è®¡

### 2.1 æ¶æ„æ¼”è¿›è·¯çº¿

```
å½“å‰æ¶æ„ (v3.1)                    ç›®æ ‡æ¶æ„ (v4.0)
================                   ================

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Routers   â”‚                   â”‚      API Gateway        â”‚
â”‚  (ä¸šåŠ¡æ··æ‚)  â”‚                   â”‚  Auth/RateLimit/Log    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                      â”‚
       â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                          â”‚      Middleware         â”‚
       â”‚                          â”‚  Cookie/Retry/Circuit   â”‚
       â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Services   â”‚      ====>       â”‚      Use Cases          â”‚
â”‚ (ç›´æ¥è€¦åˆ)   â”‚                   â”‚  SearchUC/DetailUC/... â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                      â”‚
       â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                          â”‚    Domain Services      â”‚
       â”‚                          â”‚  Crawler/Cookie/Media   â”‚
       â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Utils     â”‚                   â”‚    Infrastructure       â”‚
â”‚ (å·¥å…·æ•£è½)   â”‚                   â”‚  Proxy/Browser/Store   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 å…­è¾¹å½¢æ¶æ„è®¾è®¡

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚           Driving Adapters          â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”‚
                    â”‚  â”‚  HTTP   â”‚ â”‚  n8n    â”‚ â”‚  CLI  â”‚ â”‚
                    â”‚  â”‚  API    â”‚ â”‚ Webhook â”‚ â”‚       â”‚ â”‚
                    â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”˜ â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”˜
                            â”‚           â”‚          â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
                    â”‚              Ports                  â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
                    â”‚  â”‚     Application Services     â”‚   â”‚
                    â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â” â”‚   â”‚
                    â”‚  â”‚  â”‚Search â”‚ â”‚Extractâ”‚ â”‚...â”‚ â”‚   â”‚
                    â”‚  â”‚  â”‚  UC   â”‚ â”‚  UC   â”‚ â”‚   â”‚ â”‚   â”‚
                    â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜ â”‚   â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                    â”‚                 â”‚                   â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
                    â”‚  â”‚       Domain Core           â”‚   â”‚
                    â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
                    â”‚  â”‚  â”‚Crawler â”‚ â”‚CookieManagerâ”‚  â”‚   â”‚
                    â”‚  â”‚  â”‚Service â”‚ â”‚            â”‚  â”‚   â”‚
                    â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                    â”‚              Ports                  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚          Driven Adapters            â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                    â”‚  â”‚ Feishu  â”‚ â”‚ Redis â”‚ â”‚  XHS   â”‚  â”‚
                    â”‚  â”‚  Store  â”‚ â”‚ Cache â”‚ â”‚  API   â”‚  â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                    â”‚  â”‚  Proxy  â”‚ â”‚Browserâ”‚ â”‚  OSS   â”‚  â”‚
                    â”‚  â”‚  Pool   â”‚ â”‚Managerâ”‚ â”‚ Store  â”‚  â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ä¸‰ã€åˆ†å±‚ä¼˜åŒ–è¯¦è§£

### 3.1 APIç½‘å…³å±‚ä¼˜åŒ–

**å½“å‰é—®é¢˜**: æ— è®¤è¯ã€æ— é™æµã€æ—¥å¿—åˆ†æ•£

**ä¼˜åŒ–æ–¹æ¡ˆ**:

```python
# media_crawler_api/gateway/middleware.py

from fastapi import Request, HTTPException
from starlette.middleware.base import BaseHTTPMiddleware
import time

class APIGateway(BaseHTTPMiddleware):
    """APIç½‘å…³ä¸­é—´ä»¶"""

    async def dispatch(self, request: Request, call_next):
        start_time = time.time()
        request_id = self._generate_request_id()

        # 1. è®¤è¯æ£€æŸ¥
        if not await self._authenticate(request):
            raise HTTPException(status_code=401, detail="Unauthorized")

        # 2. é€Ÿç‡é™åˆ¶
        if not await self._check_rate_limit(request):
            raise HTTPException(status_code=429, detail="Too Many Requests")

        # 3. è®¾ç½®è¯·æ±‚ä¸Šä¸‹æ–‡
        request.state.request_id = request_id
        request.state.start_time = start_time

        # 4. æ‰§è¡Œè¯·æ±‚
        response = await call_next(request)

        # 5. æ·»åŠ å“åº”å¤´
        response.headers["X-Request-ID"] = request_id
        response.headers["X-Response-Time"] = f"{(time.time() - start_time)*1000:.2f}ms"

        return response

    async def _authenticate(self, request: Request) -> bool:
        """API Keyè®¤è¯"""
        api_key = request.headers.get("X-API-Key")
        if not api_key:
            return request.url.path in ["/health", "/ready", "/live"]
        return api_key == settings.API_KEY

    async def _check_rate_limit(self, request: Request) -> bool:
        """é€Ÿç‡é™åˆ¶æ£€æŸ¥"""
        client_ip = request.client.host
        return await rate_limiter.check(client_ip)
```

### 3.2 ä¸­é—´ä»¶å±‚è®¾è®¡

**å½“å‰é—®é¢˜**: Cookieè·å–/å¼‚å¸¸å¤„ç†é€»è¾‘æ•£è½åœ¨è·¯ç”±å±‚

**ä¼˜åŒ–æ–¹æ¡ˆ**: æå–ä¸ºç‹¬ç«‹ä¸­é—´ä»¶

```python
# media_crawler_api/middleware/cookie_middleware.py

from functools import wraps
from typing import Callable, Optional

class CookieMiddleware:
    """Cookieç®¡ç†ä¸­é—´ä»¶"""

    def __init__(self, cookie_manager: CookieManager):
        self.cookie_manager = cookie_manager

    def with_cookie(self, platform: str = "xhs"):
        """è£…é¥°å™¨: è‡ªåŠ¨ç®¡ç†Cookieè·å–å’Œæ ‡è®°"""
        def decorator(func: Callable):
            @wraps(func)
            async def wrapper(*args, **kwargs):
                # 1. è·å–Cookie
                cookie = await self.cookie_manager.acquire(platform)
                if not cookie:
                    raise CookieExhaustedException()

                try:
                    # 2. æ³¨å…¥Cookieåˆ°kwargs
                    kwargs['cookie'] = cookie

                    # 3. æ‰§è¡Œä¸šåŠ¡é€»è¾‘
                    result = await func(*args, **kwargs)

                    # 4. æ ‡è®°æˆåŠŸ
                    await self.cookie_manager.mark_used(
                        cookie.name,
                        success_count=1
                    )
                    return result

                except Exception as e:
                    # 5. æ ‡è®°å¤±è´¥
                    await self.cookie_manager.mark_used(
                        cookie.name,
                        error_count=1
                    )
                    raise

            return wrapper
        return decorator


# ä½¿ç”¨æ–¹å¼
class SearchUseCase:
    def __init__(self, cookie_middleware: CookieMiddleware):
        self.cookie = cookie_middleware

    @cookie_middleware.with_cookie(platform="xhs")
    async def execute(self, keyword: str, cookie: Cookie = None):
        # Cookieè‡ªåŠ¨æ³¨å…¥ï¼Œæ— éœ€æ‰‹åŠ¨ç®¡ç†
        return await self.crawler.search(keyword, cookie)
```

### 3.3 å¼‚å¸¸å¤„ç†ç»Ÿä¸€åŒ–

**å½“å‰é—®é¢˜**: ç›¸åŒå¼‚å¸¸å¤„ç†é€»è¾‘é‡å¤5+æ¬¡

**ä¼˜åŒ–æ–¹æ¡ˆ**:

```python
# media_crawler_api/middleware/error_handler.py

from fastapi import Request
from fastapi.responses import JSONResponse
from typing import Dict, Type

class ErrorHandler:
    """ç»Ÿä¸€å¼‚å¸¸å¤„ç†å™¨"""

    # å¼‚å¸¸ -> é”™è¯¯ç æ˜ å°„
    EXCEPTION_MAPPING: Dict[Type[Exception], tuple] = {
        CookieExhaustedException: (ErrorCode.COOKIE_EXHAUSTED, 503),
        CookieInvalidException: (ErrorCode.COOKIE_INVALID, 401),
        TimeoutError: (ErrorCode.TIMEOUT_ERROR, 504),
        PlatformException: (ErrorCode.PLATFORM_ERROR, 502),
        ValidationError: (ErrorCode.INVALID_INPUT, 400),
    }

    async def __call__(self, request: Request, exc: Exception) -> JSONResponse:
        error_code, status_code = self._map_exception(exc)

        return JSONResponse(
            status_code=status_code,
            content={
                "success": False,
                "error": {
                    "code": error_code.value,
                    "message": self._safe_message(exc),
                    "retryable": error_code in RETRYABLE_ERRORS
                },
                "meta": {
                    "request_id": getattr(request.state, 'request_id', None),
                    "timestamp": datetime.utcnow().isoformat()
                }
            }
        )

    def _map_exception(self, exc: Exception) -> tuple:
        for exc_type, mapping in self.EXCEPTION_MAPPING.items():
            if isinstance(exc, exc_type):
                return mapping
        return (ErrorCode.INTERNAL_ERROR, 500)

    def _safe_message(self, exc: Exception) -> str:
        """å®‰å…¨çš„é”™è¯¯æ¶ˆæ¯ï¼ˆä¸æš´éœ²å†…éƒ¨ç»†èŠ‚ï¼‰"""
        if settings.DEBUG:
            return str(exc)
        return "An error occurred"


# æ³¨å†Œåˆ°FastAPI
app.add_exception_handler(Exception, ErrorHandler())
```

---

## å››ã€æ€§èƒ½ä¼˜åŒ–æ–¹æ¡ˆ

### 4.1 CookieæŸ¥è¯¢ä¼˜åŒ–: O(n) â†’ O(1)

**å½“å‰é—®é¢˜**:
```python
# æ¯æ¬¡è¯·æ±‚éƒ½éå†æ‰€æœ‰Cookie
candidates = [c for c in self._cookies.values() if c.is_available()]
candidates.sort(key=lambda c: (-c.priority, c.daily_used))
```

**ä¼˜åŒ–æ–¹æ¡ˆ**:

```python
# media_crawler_api/services/cookie_optimized.py

import heapq
from collections import defaultdict
from dataclasses import dataclass, field
from typing import Dict, List, Optional

@dataclass(order=True)
class PrioritizedCookie:
    """ä¼˜å…ˆçº§CookieåŒ…è£…"""
    priority_key: tuple = field(compare=True)  # (-priority, daily_used)
    cookie: Cookie = field(compare=False)


class OptimizedCookieManager:
    """ä¼˜åŒ–åçš„Cookieç®¡ç†å™¨"""

    def __init__(self):
        # æŒ‰å¹³å°åˆ†ç»„çš„ä¼˜å…ˆçº§å †
        self._heaps: Dict[str, List[PrioritizedCookie]] = defaultdict(list)
        # æŒ‰åç§°ç´¢å¼•
        self._index: Dict[str, Cookie] = {}
        # åˆ†å¹³å°é”
        self._locks: Dict[str, asyncio.Lock] = defaultdict(asyncio.Lock)

    async def acquire(self, platform: str) -> Optional[Cookie]:
        """O(log n) è·å–æœ€ä¼˜Cookie"""
        async with self._locks[platform]:
            heap = self._heaps[platform]

            while heap:
                # O(log n) å¼¹å‡ºæœ€ä¼˜
                item = heapq.heappop(heap)
                cookie = item.cookie

                # æ£€æŸ¥æ˜¯å¦å¯ç”¨
                if cookie.is_available():
                    # æ›´æ–°ä½¿ç”¨è®¡æ•°åé‡æ–°å…¥å †
                    cookie.daily_used += 1
                    self._push(platform, cookie)
                    return cookie

            return None

    def _push(self, platform: str, cookie: Cookie):
        """å…¥å †"""
        item = PrioritizedCookie(
            priority_key=(-cookie.priority, cookie.daily_used),
            cookie=cookie
        )
        heapq.heappush(self._heaps[platform], item)

    async def add(self, cookie: Cookie):
        """æ·»åŠ Cookie"""
        self._index[cookie.name] = cookie
        self._push(cookie.platform, cookie)
```

**æ€§èƒ½å¯¹æ¯”**:

| æ“ä½œ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å |
|------|--------|--------|
| è·å–Cookie | O(n) + O(n log n) | O(log n) |
| 1000ä¸ªCookie | ~10ms | ~0.1ms |

### 4.2 HTTPè¿æ¥æ± å¤ç”¨

**å½“å‰é—®é¢˜**:
```python
# æ¯æ¬¡è¯·æ±‚åˆ›å»ºæ–°Session
async with aiohttp.ClientSession() as session:
    ...
```

**ä¼˜åŒ–æ–¹æ¡ˆ**:

```python
# media_crawler_api/infra/http_client.py

import aiohttp
from contextlib import asynccontextmanager
from typing import Optional

class HTTPClientPool:
    """HTTPè¿æ¥æ± ç®¡ç†"""

    def __init__(
        self,
        pool_size: int = 100,
        timeout: int = 30,
        keepalive_timeout: int = 60
    ):
        self.pool_size = pool_size
        self.timeout = aiohttp.ClientTimeout(total=timeout)
        self.keepalive_timeout = keepalive_timeout
        self._session: Optional[aiohttp.ClientSession] = None

    async def get_session(self) -> aiohttp.ClientSession:
        """è·å–å…±äº«Session"""
        if self._session is None or self._session.closed:
            connector = aiohttp.TCPConnector(
                limit=self.pool_size,
                keepalive_timeout=self.keepalive_timeout,
                enable_cleanup_closed=True
            )
            self._session = aiohttp.ClientSession(
                connector=connector,
                timeout=self.timeout
            )
        return self._session

    async def close(self):
        """å…³é—­è¿æ¥æ± """
        if self._session:
            await self._session.close()
            self._session = None

    @asynccontextmanager
    async def request(self, method: str, url: str, **kwargs):
        """è¯·æ±‚ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        session = await self.get_session()
        async with session.request(method, url, **kwargs) as response:
            yield response


# é›†æˆåˆ°CrawlerService
class CrawlerService:
    def __init__(self, http_client: HTTPClientPool):
        self.http = http_client

    async def search(self, ...):
        async with self.http.request(
            "POST",
            f"{self.base_url}/api/xhs/search",
            json={...},
            headers={...}
        ) as resp:
            return await resp.json()
```

**æ€§èƒ½å¯¹æ¯”**:

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å |
|------|--------|--------|
| è¿æ¥å»ºç«‹ | æ¯æ¬¡è¯·æ±‚ | å¤ç”¨ |
| SSLæ¡æ‰‹ | æ¯æ¬¡è¯·æ±‚ | å¤ç”¨ |
| å»¶è¿Ÿ | +100-300ms | 0ms |
| å¹¶å‘10è¯·æ±‚ | ~3s | ~0.3s |

### 4.3 æ‰¹é‡è¯·æ±‚å¹¶å‘åŒ–

**å½“å‰é—®é¢˜**:
```python
# ä¸²è¡Œå¤„ç†
for note_id in body.note_ids:
    detail = await crawler.get_note_detail(note_id)
```

**ä¼˜åŒ–æ–¹æ¡ˆ**:

```python
# media_crawler_api/services/batch_processor.py

import asyncio
from typing import List, TypeVar, Callable, Any

T = TypeVar('T')

class BatchProcessor:
    """æ‰¹é‡è¯·æ±‚å¹¶å‘å¤„ç†å™¨"""

    def __init__(
        self,
        max_concurrency: int = 5,
        timeout_per_item: float = 15.0
    ):
        self.semaphore = asyncio.Semaphore(max_concurrency)
        self.timeout = timeout_per_item

    async def process(
        self,
        items: List[Any],
        handler: Callable,
        **kwargs
    ) -> List[dict]:
        """å¹¶å‘å¤„ç†æ‰¹é‡è¯·æ±‚"""

        async def process_one(item) -> dict:
            async with self.semaphore:
                try:
                    result = await asyncio.wait_for(
                        handler(item, **kwargs),
                        timeout=self.timeout
                    )
                    return {"id": item, "success": True, "data": result}
                except asyncio.TimeoutError:
                    return {"id": item, "success": False, "error": "TIMEOUT"}
                except Exception as e:
                    return {"id": item, "success": False, "error": str(e)}

        tasks = [process_one(item) for item in items]
        return await asyncio.gather(*tasks)


# ä½¿ç”¨æ–¹å¼
batch = BatchProcessor(max_concurrency=5)
results = await batch.process(
    items=note_ids,
    handler=crawler.get_note_detail
)
```

**æ€§èƒ½å¯¹æ¯”**:

| åœºæ™¯ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å |
|------|--------|--------|
| 20æ¡ç¬”è®° | 20 Ã— 15s = 300s | 15s (å¹¶å‘5) |
| æå‡ | - | **20å€** |

---

## äº”ã€åŸºç¡€è®¾æ–½å±‚ä¼˜åŒ–

### 5.1 ä»£ç†æ± æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ProxyPool                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Provider  â”‚    â”‚   Provider  â”‚    â”‚   Provider  â”‚ â”‚
â”‚  â”‚  (å¿«ä»£ç†)    â”‚    â”‚  (è‡ªå®šä¹‰)    â”‚    â”‚  (èŠéº»)     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                  â”‚                  â”‚         â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                            â”‚                            â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚                    â”‚  Proxy Queue  â”‚                   â”‚
â”‚                    â”‚  (ä¼˜å…ˆçº§é˜Ÿåˆ—)  â”‚                   â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                            â”‚                            â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚         â”‚                  â”‚                  â”‚         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Validator  â”‚    â”‚  Rotator    â”‚    â”‚  Monitor   â”‚ â”‚
â”‚  â”‚  (å¯ç”¨éªŒè¯)  â”‚    â”‚  (è½®æ¢ç­–ç•¥)  â”‚    â”‚  (å¥åº·ç›‘æ§) â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 å­˜å‚¨å±‚æŠ½è±¡

```python
# media_crawler_api/store/interface.py

from abc import ABC, abstractmethod
from typing import Optional, List, Dict, Any

class StorageInterface(ABC):
    """å­˜å‚¨å±‚æ¥å£"""

    # ========== Cookie å­˜å‚¨ ==========

    @abstractmethod
    async def get_cookie(self, name: str) -> Optional[Dict]: ...

    @abstractmethod
    async def save_cookie(self, cookie: Dict) -> str: ...

    @abstractmethod
    async def list_cookies(
        self,
        platform: str,
        status: str = "active"
    ) -> List[Dict]: ...

    @abstractmethod
    async def update_cookie(self, name: str, updates: Dict) -> bool: ...

    # ========== ç¬”è®°å­˜å‚¨ ==========

    @abstractmethod
    async def save_note(self, note: Dict) -> str: ...

    @abstractmethod
    async def get_note(self, note_id: str) -> Optional[Dict]: ...

    @abstractmethod
    async def note_exists(self, note_id: str) -> bool: ...

    # ========== è¿›åº¦å­˜å‚¨ ==========

    @abstractmethod
    async def save_progress(self, key: str, progress: Dict) -> None: ...

    @abstractmethod
    async def get_progress(self, key: str) -> Optional[Dict]: ...


# å®ç°ç±»
class FeishuStorage(StorageInterface):
    """é£ä¹¦å¤šç»´è¡¨æ ¼å­˜å‚¨"""
    ...

class SQLiteStorage(StorageInterface):
    """SQLiteæœ¬åœ°å­˜å‚¨"""
    ...

class RedisStorage(StorageInterface):
    """Redisç¼“å­˜å­˜å‚¨"""
    ...
```

### 5.3 é…ç½®ç®¡ç†ä¼˜åŒ–

```python
# media_crawler_api/config/settings.py

from pydantic_settings import BaseSettings
from functools import lru_cache
from typing import Dict, List, Optional

class Settings(BaseSettings):
    """åº”ç”¨é…ç½® - æ”¯æŒç¯å¢ƒå˜é‡è¦†ç›–"""

    # ========== åº”ç”¨é…ç½® ==========
    APP_NAME: str = "MediaCrawler API"
    APP_VERSION: str = "4.0.0"
    DEBUG: bool = False
    ENV: str = "production"

    # ========== APIé…ç½® ==========
    API_HOST: str = "0.0.0.0"
    API_PORT: int = 8080
    API_KEY: Optional[str] = None
    API_RATE_LIMIT: int = 100  # æ¯åˆ†é’Ÿ

    # ========== è¶…æ—¶é…ç½® ==========
    TIMEOUT_SEARCH: int = 30
    TIMEOUT_DETAIL: int = 15
    TIMEOUT_BATCH: int = 60
    TIMEOUT_COMMENTS: int = 15

    # ========== Cookieé…ç½® ==========
    COOKIE_COOLING_MINUTES: int = 30
    COOKIE_MAX_CONSECUTIVE_ERRORS: int = 3
    COOKIE_MAX_TOTAL_ERRORS: int = 10
    COOKIE_DAILY_LIMIT: int = 100

    # ========== ä»£ç†é…ç½® ==========
    PROXY_ENABLED: bool = False
    PROXY_PROVIDER: str = "custom"
    PROXY_LIST: List[str] = []
    PROXY_POOL_SIZE: int = 5
    PROXY_REFRESH_INTERVAL: int = 300

    # ========== é‡è¯•é…ç½® ==========
    RETRY_MAX_ATTEMPTS: int = 3
    RETRY_MIN_WAIT: float = 2.0
    RETRY_MAX_WAIT: float = 30.0

    # ========== å¹¶å‘é…ç½® ==========
    BATCH_MAX_CONCURRENCY: int = 5
    HTTP_POOL_SIZE: int = 100
    HTTP_KEEPALIVE: int = 60

    # ========== å­˜å‚¨é…ç½® ==========
    STORAGE_BACKEND: str = "feishu"  # feishu|sqlite|redis

    # ========== å®‰å…¨é…ç½® ==========
    COOKIE_MASTER_KEY: str = ""
    LOG_LEVEL: str = "INFO"

    class Config:
        env_file = ".env"
        env_prefix = "MC_"  # ç¯å¢ƒå˜é‡å‰ç¼€


@lru_cache()
def get_settings() -> Settings:
    """è·å–é…ç½®å•ä¾‹ï¼ˆç¼“å­˜ï¼‰"""
    return Settings()
```

---

## å…­ã€æ–°ç›®å½•ç»“æ„

```
mediacrawler-api/
â”œâ”€â”€ media_crawler_api/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                     # åº”ç”¨å…¥å£
â”‚   â”‚
â”‚   â”œâ”€â”€ gateway/                    # ğŸ†• APIç½‘å…³å±‚
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ middleware.py           # è®¤è¯/é™æµ/æ—¥å¿—
â”‚   â”‚   â””â”€â”€ rate_limiter.py         # é€Ÿç‡é™åˆ¶å™¨
â”‚   â”‚
â”‚   â”œâ”€â”€ middleware/                 # ğŸ†• ä¸šåŠ¡ä¸­é—´ä»¶
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ cookie.py               # Cookieè‡ªåŠ¨ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ retry.py                # é‡è¯•ç­–ç•¥
â”‚   â”‚   â”œâ”€â”€ circuit_breaker.py      # æ–­è·¯å™¨
â”‚   â”‚   â””â”€â”€ error_handler.py        # ç»Ÿä¸€å¼‚å¸¸å¤„ç†
â”‚   â”‚
â”‚   â”œâ”€â”€ use_cases/                  # ğŸ†• ç”¨ä¾‹å±‚
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ search.py               # æœç´¢ç”¨ä¾‹
â”‚   â”‚   â”œâ”€â”€ extract.py              # è¯¦æƒ…æå–ç”¨ä¾‹
â”‚   â”‚   â”œâ”€â”€ creator.py              # åˆ›ä½œè€…ç”¨ä¾‹
â”‚   â”‚   â””â”€â”€ batch.py                # æ‰¹é‡å¤„ç†ç”¨ä¾‹
â”‚   â”‚
â”‚   â”œâ”€â”€ domain/                     # ğŸ†• é¢†åŸŸå±‚
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ entities/               # å®ä½“
â”‚   â”‚   â”‚   â”œâ”€â”€ cookie.py
â”‚   â”‚   â”‚   â”œâ”€â”€ note.py
â”‚   â”‚   â”‚   â””â”€â”€ creator.py
â”‚   â”‚   â”œâ”€â”€ services/               # é¢†åŸŸæœåŠ¡
â”‚   â”‚   â”‚   â”œâ”€â”€ crawler.py
â”‚   â”‚   â”‚   â””â”€â”€ cookie_manager.py
â”‚   â”‚   â””â”€â”€ exceptions.py           # é¢†åŸŸå¼‚å¸¸
â”‚   â”‚
â”‚   â”œâ”€â”€ infra/                      # ğŸ†• åŸºç¡€è®¾æ–½å±‚
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ http_client.py          # HTTPè¿æ¥æ± 
â”‚   â”‚   â”œâ”€â”€ proxy_pool.py           # ä»£ç†æ± 
â”‚   â”‚   â”œâ”€â”€ browser_manager.py      # æµè§ˆå™¨ç®¡ç†
â”‚   â”‚   â””â”€â”€ cache.py                # ç¼“å­˜ç®¡ç†
â”‚   â”‚
â”‚   â”œâ”€â”€ store/                      # ğŸ†• å­˜å‚¨å±‚
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ interface.py            # å­˜å‚¨æ¥å£
â”‚   â”‚   â”œâ”€â”€ feishu.py               # é£ä¹¦å®ç°
â”‚   â”‚   â”œâ”€â”€ sqlite.py               # SQLiteå®ç°
â”‚   â”‚   â””â”€â”€ redis.py                # Rediså®ç°
â”‚   â”‚
â”‚   â”œâ”€â”€ api/                        # é‡æ„åçš„APIå±‚
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ search.py
â”‚   â”‚   â”‚   â”œâ”€â”€ note.py
â”‚   â”‚   â”‚   â”œâ”€â”€ creator.py
â”‚   â”‚   â”‚   â””â”€â”€ health.py
â”‚   â”‚   â””â”€â”€ schemas/                # è¯·æ±‚/å“åº”æ¨¡å‹
â”‚   â”‚       â”œâ”€â”€ request.py
â”‚   â”‚       â””â”€â”€ response.py
â”‚   â”‚
â”‚   â”œâ”€â”€ config/                     # ğŸ†• é…ç½®ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ settings.py
â”‚   â”‚
â”‚   â””â”€â”€ utils/                      # å·¥å…·å±‚
â”‚       â”œâ”€â”€ crypto.py
â”‚       â”œâ”€â”€ logging.py
â”‚       â””â”€â”€ alerting.py
â”‚
â”œâ”€â”€ tests/                          # æµ‹è¯•
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ e2e/
â”‚
â””â”€â”€ docs/
```

---

## ä¸ƒã€ä¾èµ–æ³¨å…¥å®¹å™¨

```python
# media_crawler_api/container.py

from dependency_injector import containers, providers
from .config.settings import Settings
from .infra.http_client import HTTPClientPool
from .infra.proxy_pool import ProxyPool
from .domain.services.crawler import CrawlerService
from .domain.services.cookie_manager import CookieManager
from .store.feishu import FeishuStorage
from .store.sqlite import SQLiteStorage

class Container(containers.DeclarativeContainer):
    """ä¾èµ–æ³¨å…¥å®¹å™¨"""

    # é…ç½®
    config = providers.Singleton(Settings)

    # åŸºç¡€è®¾æ–½
    http_client = providers.Singleton(
        HTTPClientPool,
        pool_size=config.provided.HTTP_POOL_SIZE,
        timeout=config.provided.TIMEOUT_SEARCH
    )

    proxy_pool = providers.Singleton(
        ProxyPool,
        enabled=config.provided.PROXY_ENABLED,
        provider=config.provided.PROXY_PROVIDER
    )

    # å­˜å‚¨
    storage = providers.Selector(
        config.provided.STORAGE_BACKEND,
        feishu=providers.Singleton(FeishuStorage),
        sqlite=providers.Singleton(SQLiteStorage)
    )

    # é¢†åŸŸæœåŠ¡
    cookie_manager = providers.Singleton(
        CookieManager,
        storage=storage
    )

    crawler_service = providers.Singleton(
        CrawlerService,
        http_client=http_client,
        proxy_pool=proxy_pool
    )


# ä½¿ç”¨
container = Container()
crawler = container.crawler_service()
```

---

## å…«ã€å®æ–½ä¼˜å…ˆçº§

### Phase 1: åŸºç¡€ä¼˜åŒ– (Week 1)

| ä»»åŠ¡ | å½±å“ | å¤æ‚åº¦ | æ”¶ç›Š |
|------|------|--------|------|
| é…ç½®ç®¡ç†ç»Ÿä¸€ | å…¨å±€ | ä½ | é«˜ |
| HTTPè¿æ¥æ±  | æ€§èƒ½ | ä¸­ | é«˜ |
| å¼‚å¸¸å¤„ç†ç»Ÿä¸€ | ä»£ç è´¨é‡ | ä¸­ | é«˜ |
| CookieæŸ¥è¯¢ä¼˜åŒ– | æ€§èƒ½ | ä¸­ | é«˜ |

### Phase 2: æ¶æ„é‡æ„ (Week 2-3)

| ä»»åŠ¡ | å½±å“ | å¤æ‚åº¦ | æ”¶ç›Š |
|------|------|--------|------|
| ä¸­é—´ä»¶å±‚æå– | æ¶æ„ | é«˜ | é«˜ |
| ç”¨ä¾‹å±‚è®¾è®¡ | å¯æ‰©å±•æ€§ | é«˜ | é«˜ |
| å­˜å‚¨å±‚æŠ½è±¡ | çµæ´»æ€§ | ä¸­ | ä¸­ |
| ä¾èµ–æ³¨å…¥ | å¯æµ‹è¯•æ€§ | ä¸­ | é«˜ |

### Phase 3: åŠŸèƒ½å¢å¼º (Week 4)

| ä»»åŠ¡ | å½±å“ | å¤æ‚åº¦ | æ”¶ç›Š |
|------|------|--------|------|
| ä»£ç†æ± å®ç° | ç¨³å®šæ€§ | é«˜ | é«˜ |
| æ‰¹é‡å¹¶å‘å¤„ç† | æ€§èƒ½ | ä¸­ | é«˜ |
| APIè®¤è¯ | å®‰å…¨æ€§ | ä¸­ | é«˜ |
| æ–­è·¯å™¨æ¨¡å¼ | ç¨³å®šæ€§ | ä¸­ | ä¸­ |

---

## ä¹ã€é¢„æœŸæ”¶ç›Š

### æ€§èƒ½æå‡

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡ |
|------|--------|--------|------|
| Cookieè·å– | 10ms | 0.1ms | **100x** |
| HTTPè¯·æ±‚å»¶è¿Ÿ | +300ms | 0ms | **âˆ** |
| æ‰¹é‡20æ¡è¯·æ±‚ | 300s | 15s | **20x** |
| å¹¶å‘èƒ½åŠ› | 1 | 5+ | **5x** |

### ä»£ç è´¨é‡

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å |
|------|--------|--------|
| ä»£ç é‡å¤ç‡ | ~15% | <5% |
| æµ‹è¯•è¦†ç›–ç‡ | 0% | >70% |
| è€¦åˆåº¦ | é«˜ | ä½ |
| æ–°åŠŸèƒ½å¼€å‘æ—¶é—´ | é•¿ | çŸ­ |

### è¿ç»´èƒ½åŠ›

| èƒ½åŠ› | ä¼˜åŒ–å‰ | ä¼˜åŒ–å |
|------|--------|--------|
| é…ç½®ä¿®æ”¹ | é‡æ–°éƒ¨ç½² | ç¯å¢ƒå˜é‡ |
| å­˜å‚¨åˆ‡æ¢ | æ”¹ä»£ç  | é…ç½®åˆ‡æ¢ |
| é—®é¢˜å®šä½ | å›°éš¾ | request_idè¿½è¸ª |
| æ‰©å®¹ | å•è¿›ç¨‹ | å¤šå®ä¾‹ |

---

> æ–‡æ¡£ç‰ˆæœ¬: v1.0
> åˆ›å»ºæ—¶é—´: 2025-12-16
